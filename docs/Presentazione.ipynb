{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positive Chat \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obiettivo del progetto\n",
    "Chi passa qualche ora al PC, soprattutto in giovane età e non per solo scopi lavorativi, sicuramente si è imbattuto in qualche servizio di chating. Spesso tantissime conversazione degenerano in flame e ciò rendono la chat posti particolarmente negativi dove vivere. Soprattutto se ciò che si cerca è solamente un po' di svago e sano confronto di idee. \n",
    "L'obiettivo sarà quello di creare delle chat di contenuti e utenti **positivi**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sviluppo\n",
    "\n",
    "Per realizzare tutto ciò utilizzerò un sistema di Sentiment Analysis. In particolare la libreria, già testata, adoperata è [VaderSentimentJava](https://github.com/apanimesh061/VaderSentimentJava), ovvero un porting in Java della libreria originale VADER (Valence Aware Dictionary and sEntiment Reasoner). Inoltre, Positive Chat è stato creato con l'utilizzo di potenti servizi e strumenti. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tecnologie Utilizzate\n",
    "\n",
    "| Servizio | Scopo |  | \n",
    "| :------- | :----------- | ----- | \n",
    "| **Spring Boot**  | Framework for Reactive and API Data Ingestor| <img src=\"./imgs/springlogo.svg\" width=\"100\" height=\"60\"/> |\n",
    "| **Apache Kafka** | Data Streamer | <img src=\"./imgs/kafka.png\" width=\"100\" height=\"60\"/> |\n",
    "| **Apache Zookpeer** | Orchestation | <img src=\"./imgs/zookeeperlogo.svg\" width=\"100\" height=\"60\"/> |\n",
    "| **Apache Spark** | Data Processing | <img src=\"./imgs/spark.png\" width=\"100\" height=\"60\"/> |\n",
    "| **Elasticsearch** | Data Indexing | <img src=\"./imgs/elasticlogo.svg\" width=\"100\" height=\"60\"/> |\n",
    "| **Kibana** | Data Visualization | <img src=\"./imgs/kibana.png\" width=\"100\" height=\"60\"/> |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architettura Positive Chat Bot\n",
    "<img src=\"./imgs/Architettura-Positive.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spring Boot e Data Ingestor - Positive Ingestor\n",
    "Spring Boot è un framework open source per scrivere applicazioni enterprise Java. Ha una logica modulare di dipendenze, infatti sono collegati numerosi progetti come Spring Reactive, Spring Data, Spring for Apache Kafka, Spring Integration e tantissimi altri moduli. In questo progetto è stato utilizzato per scrivere delle parti importanti del **Data Ingestor** ed esporre un'API per facilitarne l'utilizzo a dei Client esterni.\n",
    "Il data ingestor è stato basato su un architettura API di tipo RESTful, riceve tramite i suoi endpoint qualsiasi messaggio, ben formato, che sia di tipo JSON. Questo aspetto permette una scalabilità ampia agli utenti, con la possibilità quindi di adattarsi a qualsiasi piattaforma di chatting e messaggistica che dispongono di API potenti (un esempio è Telegram, ecco perché come esempio vedremo questa piattaforma). Non esclude, quindi, servizi IRC, Slack, Discord, Messenger, Whatsapp, Twitch, YouTube e tanto altro. \n",
    "\n",
    "Vediamo gli endpoint tramite degli esempi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "myRequestBody = {'platform':'telegram', 'userId':'42', 'message':'This is a simply positive message', 'groupId':'33'}\n",
    "response = requests.post(\"http://localhost:9000/api/v1/send/telegram-message\", json=myRequestBody)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true\n",
      "[{\"platform\":\"telegram\",\"userId\":\"42\",\"message\":\"ban\",\"groupId\":\"33\"}]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "myRequestBody = {'platform':'telegram', 'userId':'42', 'message':'I hate all world and If I were fire, I would burn the world;', 'groupId':'33'}\n",
    "response = requests.post(\"http://localhost:9000/api/v1/send/telegram-message\", json=myRequestBody)\n",
    "print(response.text)\n",
    "\n",
    "time.sleep(20)\n",
    "\n",
    "response = requests.get(\"http://localhost:9000/api/v1/getAction/telegram-action\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il secondo esempio di utilizzo dell'API ha generato un 'action', a seguito del messaggio che è stato inviato. \n",
    "\n",
    "Quello che accade è che l'endpoint che sta sul percorso /api/v1/**send**/{topic} produrrà un messaggio nel servizio **Kafka** (che vedremo nel dettaglio più avanti). \n",
    "L'endpoint /api/v1/**getAction**/{topic} consumerà il messaggio dal topic **Kafka**, inserendolo in una lista che sarà poi svuotata appena viene letta. \n",
    "\n",
    "L'inserimento di uno o più messaggi farà scatenare un evento. Per maggiori approfondimenti è possibile consultare la seguente voce sul [Event-driven architecture](https://en.wikipedia.org/wiki/Event-driven_architecture)\n",
    "\n",
    "\n",
    "Infine, essendo che VADER fa del sentiment analysis esclusivamente su del testo inglese, al servizio Positive Ingestor è stata demandata la logica di filtrare, ed eventualmente scartare tutti i messaggi che non sono in lingua inglese. Verranno mandati a Kafka solo i messaggi in lingua **inglese**. La libreria utilizzata per fare language detection è questa: [Language Detector](https://github.com/optimaize/language-detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italian: it\n",
      "english: en\n",
      "french: fr\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "import requests\n",
    "\n",
    "italian = detect(\"Questo è un semplice testo italiano\")\n",
    "english = detect(\"This is a simple italian text\")\n",
    "french = detect(\"Ceci est un texte français simple\")\n",
    "print(\"italian: \" + italian)\n",
    "print(\"english: \" + english)\n",
    "print(\"french: \" + french)\n",
    "\n",
    "myRequestBody = {'platform':'telegram', 'userId':'42', 'message':'Questo è un semplice testo', 'groupId':'33'}\n",
    "response = requests.post(\"http://localhost:9000/api/v1/send/telegram-message\", json=myRequestBody)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Kafka e Data Streaming\n",
    "\n",
    "### Message-Oriented Middleware (MOM) \n",
    "Si tratta di un'infrastruttura che supporta, orienta, organizza e facilita lo scambio di messaggio di sistemi e servizi distribuiti. Per chiarirci le idee immaginiamo due servizi, separati, che svolgono funzioni diverse, ma che ad un certo punto della loro esecuzione necessitano di scambiarsi informazioni. Come semplice approccio possiamo immaginare che basterebbe aprire una connessione diretta tra i due servizi. Tuttavia si tratta di un problema ricorrente e soprattutto potrebbe diventare un sistema complesso da gestire all'interno dei due servizi. Per questo, risulta spesso molto più utile, gestire la connessione e lo scambio attraverso un servizio terzo (middleware) che si mette in mezzo ai due e facilita l'obiettivo. Allo sviluppatore dei due servizi principali che vogliono comunicare viene sollevata così la responsabilità di gestire la comunicazione. Un implementazione reale di questo concetto viene definito servizio di **Message Broking** (RabbitMQ, **Apache Kafka**). \n",
    "\n",
    "Nella maggior parte dei pattern questi due (o più) servizi svolgono il ruolo di Producer e Consumer. Questi due sono accoppiati in maniera debole, cioè che i due servizi non devono conoscersi e nella maggior parte degli scenari neanche si conoscono o conoscono la quantità di Producer e Consumer sono connessi.\n",
    "\n",
    "<img src=\"./imgs/mom.png\">\n",
    "Osserviamo il diagramma di sequenza sopra.\n",
    "Come già detto il MOM si mette in mezzo ai producer e consumer e lo scambio di messaggio. Il Producer produce i messaggi, il Consumer solo quando sarà pronto a farlo consumerà i messaggi: la comunicazione avviene in maniera del tutto **asincrona**; nessuno dei due servizi rimarrà bloccato in attesa. \n",
    "\n",
    "### Data Stream\n",
    "Per data stream si intende una sequenza illimitata (continuamente alimentata) di dati che rappresentano un evento o una serie di eventi. Se pensiamo allo scenario di Positive Chat e proviamo ad immaginare che questo progetto viene ben condiviso dalle community, potremmo aspettarci una quantità di dati da gestire molto complessa e continuamente alimentata. \n",
    "Tuttavia, per far funzionare bene il prodotto è necessario che gli utenti malevoli vengono allontanati immediatamente o quasi, è perciò che si parla di **stream processing**, cioè l'analisi di questi dati (che sono sempre e solo messaggi) deve avvenire __on-the-fly__, quindi man mano che i dati sono disponibili devono essere consumati e produrre risultati ogni tot tempo (più  breve possibile, rispettando le capacità computazionali e hardware che abbiamo a disposizione). \n",
    "\n",
    "MOM e Streaming Data non sono la stessa cosa: una caratteristica che li distingue notevolmente è che il MOM contiene spesso una risposta, mentre lo Streaming Data consuma una quantità notevole di dati. \n",
    "In Positive Chat entrambi pattern sono stati utilizzati.\n",
    "\n",
    "### Apache Kafka\n",
    "Apache Kafka è una piattaforma open source di stream processing sviluppata e gestita dalla [Apache Software Foundation](https://www.apache.org/). Ha un vastissimo impiego ed è utilizzata da tantissimi leader del settore. \n",
    "Apache Kafka è in grado di pubblicare e ricevere stream di byte di qualsiasi natura. È __fault-tolerant__, e questo lo rende un sistema molto resiliente. Tramite opportune configurazione è possibile renderlo anche __durable__, cioè permette di immagazzinare i record che riceve in maniera permanente. Inoltre, permette di processare i dati in maniera real-time, quindi man mano che li riceve è possibile produrre un risultato. Tuttavia in Positive Chat demandiamo questa responsabilità al servizio di Spark (come alternativa a kSQL) che dopo vedremo.\n",
    "\n",
    "Come si può facilmente intuire, Apache Kafka, è un servizio esterno che va messo su uno o **più** cluster e anche su più data center. Questo permette di avere anche delle repliche fisiche e sfruttare dei principi di località. Questo però crea degli scenari di gestione più complessi, perché tutti questi cluster di Kafka dovranno essere orchestrati in maniera corretta. Apache Kafka usa come servizio di orchestrazione **Zookpeer** che affronteremo brevemente più avanti. \n",
    "Un concetto fondamentale in Kafka sono i **topic** e le **partition**. \n",
    "\n",
    "\n",
    "#### Topic\n",
    "Un topic rappresenta una categoria del record di byte. Immaginiamo nel caso di Positive Chat, abbiamo detto che possono collegarsi diverse tipologia di servizi di messaggistica come datasources, e ogni servizio potrebbe avere il proprio topic dedicato. I Consumatori e Produttori si legano ad uno o più topic. \n",
    "\n",
    "#### Partition\n",
    "Ogni partition è una sequenza di record immutabile e ordinata a cui vengono appesi i dati. Se N consumatori dovranno consumare in broadcast un messaggio dovranno esiste N partizioni e i consumatori dovranno collegarsi 1:1 alle partizioni. Se tutti i consumatori sono collegati ad una singola partizione, il primo disponibile consuma il messaggio. Grazie a questa caratteristica viene applicato anche un meccanismo di load balancing. \n",
    "\n",
    "\n",
    "### Apache Zookpeer e Orchestration\n",
    "Si tratta di un sistema centralizzato per: \n",
    "- mantenere le informazioni e le varie configurazioni (configuration service);\n",
    "- associare ad ogni servizio un nome (naming registry);\n",
    "- gestire la sincronizzazione tra i vari servizi (synchronization service). \n",
    "\n",
    "Diventa estremamente indispensabile quando un'applicazione services-oriented (o addirittura microservices-oriented) diventa molto complessa e con tanti componenti e copie di servizi da gestire. Apache Kafka ha necessariamente bisogno di Apache Zookpeer, essendo che l'anatomia di Kafka permette, e anzi suggerisce, di avere più cluster replicati (di buona norma, oggigiorno con l'avvento del cloud computing e ancor più degli SaaS è sempre consigliato avere il servizio replicato 3 volte). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apache Spark e Data Processing\n",
    "Apache Spark è un engine di analisi per data processing, dove possono essere analizzati in maniera performante una grandissime mole di dati. Due operazioni fondamentali che compie Spark è la __proiezioni__ e __aggregazione__ (map & reduce). \n",
    "In Positive Chat si è deciso di utilizzare Spark perché la caratteristica, che gli ha garantito un enorme platea di utilizzatori, è la **velocità**. \n",
    "Si tratta di un sistema molto più veloce perché tutto avviene in memoria RAM, a differenza di altre tecnologie che usano il disco fisico. \n",
    "Inoltre Spark è lazy: solo quando un'operazione viene richiamata lui la eseguirà. Un concetto analogo è applicato negli Stream in Java. \n",
    "Il concetto di base  che sta dietro Apache Spark è legato al **Resilient Distributed Datasets (RDD)**: una struttura dati non tipizzata, strutturata in maniera tale che i dati possono essere processati in parallelo.\n",
    "\n",
    "\n",
    "### Spark Streaming\n",
    "Spark Streaming è un estensione del core Spark API, che fornisce scalabilità e fault-tolerant di dati. \n",
    "\n",
    "Funziona che riceve dati da uno stream, poi suddivide questi dati in **micro-batch** (in base alla window scelta, nel nostro caso 5 secondi). Ogni micro-batch è processato dallo **Spark Engine**, che genera lo stream finale e convertiti in RDD. \n",
    "<img src=\"./imgs/sparkstreaming.png\"/>\n",
    "\n",
    "Spark Streaming fornisce un'astrazione di alto livello chiamata **DStream** che è una struttura dati che rappresenta uno stream discretizzato (in un certo windowing impostato da noi) continuo di dati. Un DStream è un set di RDD. \n",
    "Ad un DStream possiamo applicare tutte le funzioni che verranno applicati ad un RDD. Questi dati verranno processati in parallelo grazie a Spark Engine.\n",
    "<img src=\"./imgs/dstreamfunc.png\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch e Data Indexing\n",
    "Elasticsearch è un motore di ricerca e indicizzazione di contenuti. Può essere anche visto come un database, essendo che i dati sono immaganizzati al suo interno. Ha un architettura RESTful, quindi viene interrogato attraverso delle API REST. È distribuito e permette di scalare orizzontalmente con semplicità. \n",
    "È basato sulla libreria [Apache Lucene](https://lucene.apache.org/)\n",
    "\n",
    "Alcune caratteristiche fondamentali di Elasticsearch sono: \n",
    "- [ricerca velocissima](https://db-engines.com/en/ranking/search+engine); \n",
    "- quando viene effettuata una ricerca vengono trovati i risultati anche basandosi su un sistema di ranking, restituendo i risultati più attinenti e via via risultati meno attinenti. \n",
    "- tutto viene indicizzato; \n",
    "- sistema di resilienza. \n",
    "\n",
    "Spark contiene al suo interno un modulo (Spark to ES) per far dialogare l'ecosistema Hadoop (su cui è basato Spark) con Elastisearch in maniera veramente semplice. In Positive Chat vedremo un esempio nel servizio dedicato al data processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kibana e Data Visualization\n",
    "In Positive Chat  l'owner finale, ovvero il proprietario dell'intero servizio, avrà la possibilità di visualizzare cosa sta accadendo. Questo permetterà in futuro di effettuare dei miglioramenti. \n",
    "Per facilitare la visualizzazione e la struttura dei dati abbiamo utilizzato Kibana. Kibana è un servizio open-source di data visualization per Elastisearch. Kibana interroga il servizio di data indexing in tempo reale, e ciò permette che l'interfaccia viene aggiornata automaticamente quando vengono aggiunti i dati. \n",
    "Viene spesso utilizzato per gestire i log distribuiti di un'applicazione con lo stack **ELK**. \n",
    "Gestisce un sistema di AAA (Authentication, Authorization and Accounting) se opportunamente configurato. Gli utenti hanno la possibilità di gestire e creare degli schemi di visualizzazione, quindi riordinare i dati tramite opportuni grafici e visualizzazioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ringraziamenti e Contatti\n",
    "Questo progetto è stato realizzato come esame per la materia [TECHNOLOGIES FOR ADVANCED PROGRAMMING](http://web.dmi.unict.it/corsi/l-31/insegnamenti/?cod=16689) del professore [Salvo Nicotra](http://web.dmi.unict.it/corsi/l-31/docenti/salvatore.nicotra). \n",
    "Se qualcuno volesse contribuire o ampliare il progetto può farlo liberamente. \n",
    "Alcuni implementazione future che farò saranno: \n",
    " - creare un API più dinamica basata su autenticazione dei datasource, in Spring è molto semplice;\n",
    " - migliorare il Data Visualization, creando delle visualizzazioni utili ed efficaci all'utente e creare sistemi di AAA su Kibana.\n",
    " \n",
    "Ringrazio il docente, per aver dato uno stampo molto pratico alla materia e averci fornito contenuti davvero moderni. \n",
    "Ringrazio il mio collega e amico Danilo Santitto per avermi consigliato la libreria VADER per il Sentiment Analysis. \n",
    "\n",
    "Per qualsisiasi domanda inerente al progetto potete contattarmi su Telegram [(@Pierpaolo791)](https://t.me/Pierpaolo791) o via email (pierpaolo.pecoraio@gmail.com). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
